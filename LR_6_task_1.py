# -*- coding: utf-8 -*-
"""Untitled7.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18hXgY2pXBVdmm6LRDUDbZDL9MMFwI1QW
"""

# data.py

train_data = {
    'i am good': True,
    'i am bad': False,
    'this is very good': True,
    'this is not bad': True,
    'i am bad not good': False,
    'i am unhappy': False,
    'that was good': True,
    'i feel not bad not sad': True
}

test_data = {
    'this is happy': True,
    'i am good': True
}

import numpy as np
from data import train_data, test_data
import torch
import torch.nn as nn
import torch.optim as optim

# Побудова словника
vocab = list(set(word for sentence in train_data.keys() for word in sentence.split()))
word_to_idx = {w: i for i, w in enumerate(vocab)}
idx_to_word = {i: w for i, w in enumerate(vocab)}
vocab_size = len(vocab)

# Кодування речень
def encode_sentence(sentence):
     return [word_to_idx[word] for word in sentence.split() if word in word_to_idx]

# Перетворення речення в тензор
def sentence_to_tensor(sentence):
    indices = encode_sentence(sentence)
    tensor = torch.zeros(len(indices), 1, vocab_size)
    for i, idx in enumerate(indices):
        tensor[i][0][idx] = 1
    return tensor

# Класифікатор RNN
class RNNClassifier(nn.Module):
    def __init__(self, input_size, hidden_size, output_size):
        super(RNNClassifier, self).__init__()
        self.rnn = nn.RNN(input_size, hidden_size)
        self.fc = nn.Linear(hidden_size, output_size)

    def forward(self, input_seq):
        output, hidden = self.rnn(input_seq)
        out = self.fc(hidden.squeeze(0))
        return out

# Параметри
hidden_size = 8
output_size = 2  # позитивний / негативний

model = RNNClassifier(vocab_size, hidden_size, output_size)
loss_function = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.01)

# Навчання
for epoch in range(100):
    total_loss = 0
    for sentence, label in train_data.items():
        model.zero_grad()
        input_tensor = sentence_to_tensor(sentence)
        target = torch.tensor([0 if not label else 1])
        output = model(input_tensor)
        loss = loss_function(output, target)
        loss.backward()
        optimizer.step()
        total_loss += loss.item()
    if (epoch+1) % 10 == 0:
        print(f'Epoch {epoch+1}, Loss: {total_loss:.4f}')

# Тестування
def predict(sentence):
    with torch.no_grad():
        input_tensor = sentence_to_tensor(sentence)
        output = model(input_tensor)
        prediction = torch.argmax(torch.softmax(output, dim=1))
        return 'Positive' if prediction.item() == 1 else 'Negative'

print("\nТестування:")
for sentence, label in test_data.items():
    result = predict(sentence)
    print(f"\"{sentence}\" -> {result}")